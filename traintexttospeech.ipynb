{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:40:53.319487Z",
     "iopub.status.busy": "2025-11-05T09:40:53.318602Z",
     "iopub.status.idle": "2025-11-05T09:42:06.883844Z",
     "shell.execute_reply": "2025-11-05T09:42:06.883173Z",
     "shell.execute_reply.started": "2025-11-05T09:40:53.319462Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Collecting speechbrain==0.5.16\n",
      "  Downloading speechbrain-0.5.16-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
      "Collecting hyperpyyaml (from speechbrain==0.5.16)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (25.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (1.15.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.16) (0.31.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.16) (1.1.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->speechbrain==0.5.16) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->speechbrain==0.5.16) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->speechbrain==0.5.16) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->speechbrain==0.5.16) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->speechbrain==0.5.16) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->speechbrain==0.5.16) (2.4.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->speechbrain==0.5.16)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->speechbrain==0.5.16)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->speechbrain==0.5.16)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->speechbrain==0.5.16)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->speechbrain==0.5.16)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->speechbrain==0.5.16)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->speechbrain==0.5.16)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.16) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==0.5.16) (1.3.0)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain==0.5.16)\n",
      "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==0.5.16)\n",
      "  Downloading ruamel.yaml.clib-0.2.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain==0.5.16) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->speechbrain==0.5.16) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->speechbrain==0.5.16) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->speechbrain==0.5.16) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->speechbrain==0.5.16) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->speechbrain==0.5.16) (2024.2.0)\n",
      "Downloading speechbrain-0.5.16-py3-none-any.whl (630 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.6/630.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml.clib-0.2.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.1/738.1 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyperpyyaml, speechbrain\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2025.3.0 hyperpyyaml-1.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 speechbrain-0.5.16\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets soundfile accelerate speechbrain==0.5.16 librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:42:06.885349Z",
     "iopub.status.busy": "2025-11-05T09:42:06.885083Z",
     "iopub.status.idle": "2025-11-05T09:42:07.652022Z",
     "shell.execute_reply": "2025-11-05T09:42:07.651323Z",
     "shell.execute_reply.started": "2025-11-05T09:42:06.885316Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HF login ok\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"hello\")\n",
    "print(\"✅ HF login ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:42:24.347698Z",
     "iopub.status.busy": "2025-11-05T09:42:24.347024Z",
     "iopub.status.idle": "2025-11-05T09:45:49.664404Z",
     "shell.execute_reply": "2025-11-05T09:45:49.663447Z",
     "shell.execute_reply.started": "2025-11-05T09:42:24.347674Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a30e712d3cd4d4c81c1991a23f620fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00018-of-00027.parquet:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd70d3cb0b74eb59fe59a8eab1aec22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'transcription'],\n",
      "    num_rows: 38002\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, VerificationMode\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files=\"https://huggingface.co/datasets/NhutP/VietSpeech/resolve/main/data/train-00018-of-00027.parquet\",\n",
    "    split=\"train\",\n",
    "    verification_mode=VerificationMode.NO_CHECKS,\n",
    ")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:45:49.665793Z",
     "iopub.status.busy": "2025-11-05T09:45:49.665419Z",
     "iopub.status.idle": "2025-11-05T09:45:49.674756Z",
     "shell.execute_reply": "2025-11-05T09:45:49.674231Z",
     "shell.execute_reply.started": "2025-11-05T09:45:49.665773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'transcription'],\n",
      "    num_rows: 9500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "half_size = len(dataset) // 4\n",
    "\n",
    "# Select the first half of the dataset\n",
    "dataset = dataset.select(range(half_size))\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:45:52.492799Z",
     "iopub.status.busy": "2025-11-05T09:45:52.492464Z",
     "iopub.status.idle": "2025-11-05T09:45:52.503394Z",
     "shell.execute_reply": "2025-11-05T09:45:52.502723Z",
     "shell.execute_reply.started": "2025-11-05T09:45:52.492770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "dataset = dataset.cast_column(\"audio\", Audio(decode=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:46:56.564283Z",
     "iopub.status.busy": "2025-11-05T09:46:56.563551Z",
     "iopub.status.idle": "2025-11-05T09:47:23.996781Z",
     "shell.execute_reply": "2025-11-05T09:47:23.996010Z",
     "shell.execute_reply.started": "2025-11-05T09:46:56.564259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 09:47:09.404325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762336029.592246      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762336029.643108      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BƯỚC 3: TẢI PROCESSOR TỪ CHECKPOINT 900 ===\n",
      "Loading processor from oopssuper96/speecht5_finetuned_emirhan_tr (commit 9367721)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd0092635e84c7ba23b429903574437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/458 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6254176d9942bc9a4e0439f9152c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c1949b7efd4366ae0ac6028b233ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm_char.model:   0%|          | 0.00/238k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bcc7a24e514c3f905e7dfea7f5a18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c53647e35a45f7af93375afd2bf592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import SpeechT5ForTextToSpeech, SpeechT5Processor\n",
    "from functools import partial\n",
    "\n",
    "print(\"=== BƯỚC 3: TẢI PROCESSOR TỪ CHECKPOINT 900 ===\")\n",
    "base_repo_path = \"oopssuper96/speecht5_finetuned_emirhan_tr\"\n",
    "checkpoint_revision = \"9367721\" \n",
    "\n",
    "print(f\"Loading processor from {base_repo_path} (commit {checkpoint_revision})...\")\n",
    "processor = SpeechT5Processor.from_pretrained(\n",
    "    base_repo_path, \n",
    "    revision=checkpoint_revision\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:47:45.392227Z",
     "iopub.status.busy": "2025-11-05T09:47:45.391372Z",
     "iopub.status.idle": "2025-11-05T09:47:45.395740Z",
     "shell.execute_reply": "2025-11-05T09:47:45.395021Z",
     "shell.execute_reply.started": "2025-11-05T09:47:45.392199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = processor.tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:47:54.711146Z",
     "iopub.status.busy": "2025-11-05T09:47:54.710840Z",
     "iopub.status.idle": "2025-11-05T09:47:54.771022Z",
     "shell.execute_reply": "2025-11-05T09:47:54.770101Z",
     "shell.execute_reply.started": "2025-11-05T09:47:54.711123Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1ea5ace38741418c32123ba8d3fb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters in dataset not in tokenizer: {'à', 'ờ', 'ỷ', 'ẵ', 'ò', 'ễ', 'ỡ', 'ữ', 'ằ', 'ầ', '3', 'ộ', 'í', 'ã', 'è', 'ở', 'ể', 'ỏ', 'ứ', 'ỉ', 'ẩ', 'ớ', 'ị', 'â', 'ụ', 'ơ', 'ấ', 'ặ', 'ô', 'ũ', 'ỗ', 'ẳ', 'ạ', 'ẻ', 'ú', 'ắ', 'ẫ', 'ả', 'ẽ', 'ỹ', 'ĩ', 'ề', 'ử', 'ợ', 'ă', 'ý', 'ố', 'ọ', 'ì', 'ự', 'á', 'ủ', 'ừ', 'ồ', 'ẹ', 'ư', 'đ', 'ổ', 'ậ', 'ỳ', ' ', 'ó', 'ỵ', 'ù', 'ế', 'ệ', 'õ'}\n"
     ]
    }
   ],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"transcription\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "vocabs = dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=dataset.column_names,\n",
    ")\n",
    "\n",
    "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
    "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}\n",
    "\n",
    "print(f\"Characters in dataset not in tokenizer: {dataset_vocab - tokenizer_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:47:57.153384Z",
     "iopub.status.busy": "2025-11-05T09:47:57.152850Z",
     "iopub.status.idle": "2025-11-05T09:48:01.192164Z",
     "shell.execute_reply": "2025-11-05T09:48:01.191315Z",
     "shell.execute_reply.started": "2025-11-05T09:47:57.153360Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding normalized_text column...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cf078d6ec140d8807bcb4ad9f950f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation (except apostrophes)\n",
    "    text = re.sub(r'[^\\w\\s\\']', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    return text\n",
    "\n",
    "# Define a function to add the normalized_text column\n",
    "def add_normalized_text(example):\n",
    "    example['normalized_text'] = normalize_text(example['transcription'])\n",
    "    return example\n",
    "\n",
    "# Apply the function to the dataset\n",
    "print(\"Adding normalized_text column...\")\n",
    "dataset = dataset.map(add_normalized_text)\n",
    "\n",
    "\n",
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"normalized_text\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:48:08.613390Z",
     "iopub.status.busy": "2025-11-05T09:48:08.613144Z",
     "iopub.status.idle": "2025-11-05T09:48:08.662807Z",
     "shell.execute_reply": "2025-11-05T09:48:08.661942Z",
     "shell.execute_reply.started": "2025-11-05T09:48:08.613374Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75470f2d19d847c59929e16eed17f888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters after normalization not in tokenizer: {'à', 'ờ', 'ỷ', 'ẵ', 'ò', 'ễ', 'ỡ', 'ữ', 'ằ', 'ầ', '3', 'ộ', 'í', 'ã', 'è', 'ở', 'ể', 'ỏ', 'ứ', 'ỉ', 'ẩ', 'ớ', 'ị', 'â', 'ụ', 'ơ', 'ấ', 'ặ', 'ô', 'ũ', 'ỗ', 'ẳ', 'ạ', 'ẻ', 'ú', 'ắ', 'ẫ', 'ả', 'ẽ', 'ỹ', 'ĩ', 'ề', 'ử', 'ợ', 'ă', 'ý', 'ố', 'ọ', 'ì', 'ự', 'á', 'ủ', 'ừ', 'ồ', 'ẹ', 'ư', 'đ', 'ổ', 'ậ', 'ỳ', ' ', 'ó', 'ỵ', 'ù', 'ế', 'ệ', 'õ'}\n"
     ]
    }
   ],
   "source": [
    "vocabs = dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=dataset.column_names,\n",
    ")\n",
    "\n",
    "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
    "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}\n",
    "\n",
    "print(f\"Characters after normalization not in tokenizer: {dataset_vocab - tokenizer_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:48:11.368446Z",
     "iopub.status.busy": "2025-11-05T09:48:11.367748Z",
     "iopub.status.idle": "2025-11-05T09:48:15.641542Z",
     "shell.execute_reply": "2025-11-05T09:48:15.640830Z",
     "shell.execute_reply.started": "2025-11-05T09:48:11.368421Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1371002a324748bb01ca9c78470ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "replacements = [\n",
    "    (\"à\",\"af\"),(\"á\",\"as\"),(\"ả\",\"ar\"),(\"ã\",\"ax\"),(\"ạ\",\"aj\"),\n",
    "    \n",
    "    (\"ă\",\"ah\"),(\"ằ\",\"ahf\"),(\"ắ\",\"ahs\"),(\"ẳ\",\"ahr\"),(\"ẵ\",\"ahx\"),(\"ặ\",\"ahj\"),\n",
    "    \n",
    "    (\"â\",\"ay\"),(\"ầ\",\"ayf\"),(\"ấ\",\"ays\"),(\"ẩ\",\"ayr\"),(\"ẫ\",\"ayx\"),(\"ậ\",\"ayj\"),\n",
    "    \n",
    "    (\"è\",\"ef\"),(\"é\",\"es\"),(\"ẻ\",\"er\"),(\"ẽ\",\"ex\"),(\"ẹ\",\"ej\"),\n",
    "    \n",
    "    (\"ê\",\"ee\"),(\"ề\",\"eef\"),(\"ế\",\"ees\"),(\"ể\",\"eer\"),(\"ễ\",\"eex\"),(\"ệ\",\"eej\"),\n",
    "    \n",
    "    (\"ì\",\"if\"),(\"í\",\"is\"),(\"ỉ\",\"ir\"),(\"ĩ\",\"ix\"),(\"ị\",\"ij\"),\n",
    "    \n",
    "    (\"ò\",\"of\"),(\"ó\",\"os\"),(\"ỏ\",\"or\"),(\"õ\",\"ox\"),(\"ọ\",\"oj\"),\n",
    "    \n",
    "    (\"ô\",\"oh\"),(\"ồ\",\"ohf\"),(\"ố\",\"ohs\"),(\"ổ\",\"ohr\"),(\"ỗ\",\"ohx\"),(\"ộ\",\"ohj\"),\n",
    "\n",
    "    (\"ư\",\"uw\"),(\"ừ\",\"uwf\"),(\"ứ\",\"uws\"),(\"ử\",\"uwr\"),(\"ữ\",\"uwx\"),(\"ự\",\"uwj\"),\n",
    "\n",
    "    (\"ơ\",\"ow\"),(\"ờ\",\"owf\"),(\"ớ\",\"ows\"),(\"ở\",\"owr\"),(\"ỡ\",\"owx\"),(\"ợ\",\"owj\"),\n",
    "    \n",
    "    (\"ù\",\"uf\"),(\"ú\",\"us\"),(\"ủ\",\"ur\"),(\"ũ\",\"ux\"),(\"ụ\",\"uj\"),\n",
    "    \n",
    "    (\"ỳ\",\"yf\"),(\"ý\",\"ys\"),(\"ỷ\",\"yr\"),(\"ỹ\",\"yx\"),(\"ỵ\",\"yj\"),\n",
    "    \n",
    "    # Phụ âm \n",
    "    (\"đ\",\"d\"),\n",
    "    (\"gi\",\"z\"),\n",
    "    (\"d\",\"z\"), \n",
    "    (\"r\",\"zh\"),\n",
    "    (\"x\",\"s\"),\n",
    "    (\"s\",\"sh\"),\n",
    "    (\"tr\",\"chr\"),\n",
    "    (\"ch\",\"ch\"),\n",
    "    (\"th\",\"th\"),\n",
    "    (\"ph\",\"f\"),\n",
    "    (\"kh\",\"kh\"),\n",
    "    (\"nh\",\"nh\"),\n",
    "    (\"ng\",\"ng\"),\n",
    "    (\"gh\",\"g\"),\n",
    "]  \n",
    "def cleanup_text(inputs):\n",
    "    for src, dst in replacements:\n",
    "        inputs[\"normalized_text\"] = inputs[\"normalized_text\"].replace(src, dst)\n",
    "    return inputs\n",
    "\n",
    "print(\"Cleaning up text...\")\n",
    "dataset = dataset.map(cleanup_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:48:15.806259Z",
     "iopub.status.busy": "2025-11-05T09:48:15.805950Z",
     "iopub.status.idle": "2025-11-05T09:48:19.780515Z",
     "shell.execute_reply": "2025-11-05T09:48:19.779665Z",
     "shell.execute_reply.started": "2025-11-05T09:48:15.806239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba265960567449109c926fb3bc570455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hyperparams.yaml: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2450a95fc34145efa4b93edf8943627d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding_model.ckpt:   0%|          | 0.00/16.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9b0d8b6cce4810b66665b7ca8cc996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mean_var_norm_emb.ckpt:   0%|          | 0.00/3.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83cffe178c141dc83b6084f0535cb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "classifier.ckpt:   0%|          | 0.00/15.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ae50842d3d41a9968fbc2e3b8d877d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "label_encoder.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "speaker_model = EncoderClassifier.from_hparams(\n",
    "    source=spk_model_name,\n",
    "    run_opts={\"device\": device},\n",
    "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
    ")\n",
    "\n",
    "def create_speaker_embedding(waveform):\n",
    "    with torch.no_grad():\n",
    "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
    "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
    "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
    "    return speaker_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:48:22.216758Z",
     "iopub.status.busy": "2025-11-05T09:48:22.216466Z",
     "iopub.status.idle": "2025-11-05T09:50:11.744439Z",
     "shell.execute_reply": "2025-11-05T09:50:11.743783Z",
     "shell.execute_reply.started": "2025-11-05T09:48:22.216736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset (this may take a while)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c673e1d654f44b69a81cd9c4cfee6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import librosa\n",
    "import io\n",
    "def prepare_dataset(example):\n",
    "    audio_data = example[\"audio\"]\n",
    "\n",
    "    # Kiểm tra xem audio có bytes hay path\n",
    "    if \"bytes\" in audio_data and audio_data[\"bytes\"] is not None:\n",
    "        # Đọc từ bytes\n",
    "        audio_bytes = audio_data[\"bytes\"]\n",
    "        speech_array, sampling_rate = sf.read(io.BytesIO(audio_bytes))\n",
    "    elif \"path\" in audio_data and audio_data[\"path\"] is not None:\n",
    "        # Thử đọc từ path (nếu là đường dẫn đầy đủ)\n",
    "        try:\n",
    "            speech_array, sampling_rate = sf.read(audio_data[\"path\"])\n",
    "        except:\n",
    "            # Nếu path không hoạt động, báo lỗi rõ ràng\n",
    "            raise ValueError(f\"Cannot read audio from path: {audio_data['path']}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Audio data does not contain 'bytes' or valid 'path': {audio_data.keys()}\")\n",
    "\n",
    "    # Resample về 16kHz nếu cần\n",
    "    if sampling_rate != 16000:\n",
    "        speech_array = librosa.resample(\n",
    "            speech_array,\n",
    "            orig_sr=sampling_rate,\n",
    "            target_sr=16000\n",
    "        )\n",
    "        sampling_rate = 16000\n",
    "\n",
    "    # Process\n",
    "    processed = processor(\n",
    "        text=example[\"normalized_text\"],\n",
    "        audio_target=speech_array,\n",
    "        sampling_rate=sampling_rate,\n",
    "        return_attention_mask=False,\n",
    "    )\n",
    "\n",
    "    processed[\"labels\"] = processed[\"labels\"][0]\n",
    "    processed[\"speaker_embeddings\"] = create_speaker_embedding(speech_array)\n",
    "\n",
    "    return processed\n",
    "print(\"Processing dataset (this may take a while)...\")\n",
    "dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:50:52.526492Z",
     "iopub.status.busy": "2025-11-05T09:50:52.526216Z",
     "iopub.status.idle": "2025-11-05T09:50:52.541817Z",
     "shell.execute_reply": "2025-11-05T09:50:52.541047Z",
     "shell.execute_reply.started": "2025-11-05T09:50:52.526471Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker embeddings shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "speaker_emb = np.array(dataset[0]['speaker_embeddings'])\n",
    "print(f\"Speaker embeddings shape: {speaker_emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:50:54.606967Z",
     "iopub.status.busy": "2025-11-05T09:50:54.606419Z",
     "iopub.status.idle": "2025-11-05T09:50:54.968799Z",
     "shell.execute_reply": "2025-11-05T09:50:54.968049Z",
     "shell.execute_reply.started": "2025-11-05T09:50:54.606944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2ba5d7079b450ab2c55c99565315e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size after filtering: 9428\n",
      "Train: 8485, Test: 943\n"
     ]
    }
   ],
   "source": [
    "def is_not_too_long(input_ids):\n",
    "    return len(input_ids) < 200\n",
    "\n",
    "dataset = dataset.filter(is_not_too_long, input_columns=[\"input_ids\"])\n",
    "print(f\"Dataset size after filtering: {len(dataset)}\")\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "print(f\"Train: {len(dataset['train'])}, Test: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:50:57.736204Z",
     "iopub.status.busy": "2025-11-05T09:50:57.735921Z",
     "iopub.status.idle": "2025-11-05T09:50:57.744068Z",
     "shell.execute_reply": "2025-11-05T09:50:57.743382Z",
     "shell.execute_reply.started": "2025-11-05T09:50:57.736184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class TTSDataCollatorWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(\n",
    "        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        input_ids = [{\"input_ids\": feature[\"input_ids\"]} for feature in features]\n",
    "        label_features = [{\"input_values\": feature[\"labels\"]} for feature in features]\n",
    "        speaker_features = [feature[\"speaker_embeddings\"] for feature in features]\n",
    "\n",
    "        batch = processor.pad(\n",
    "            input_ids=input_ids, labels=label_features, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = batch[\"labels\"].masked_fill(\n",
    "            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100\n",
    "        )\n",
    "\n",
    "        del batch[\"decoder_attention_mask\"]\n",
    "\n",
    "        if model.config.reduction_factor > 1:\n",
    "            target_lengths = torch.tensor(\n",
    "                [len(feature[\"input_values\"]) for feature in label_features]\n",
    "            )\n",
    "            target_lengths = target_lengths.new(\n",
    "                [\n",
    "                    length - length % model.config.reduction_factor\n",
    "                    for length in target_lengths\n",
    "                ]\n",
    "            )\n",
    "            max_length = max(target_lengths)\n",
    "            batch[\"labels\"] = batch[\"labels\"][:, :max_length]\n",
    "\n",
    "        batch[\"speaker_embeddings\"] = torch.tensor(speaker_features)\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = TTSDataCollatorWithPadding(processor=processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:51:01.226000Z",
     "iopub.status.busy": "2025-11-05T09:51:01.225383Z",
     "iopub.status.idle": "2025-11-05T09:51:06.397697Z",
     "shell.execute_reply": "2025-11-05T09:51:06.396953Z",
     "shell.execute_reply.started": "2025-11-05T09:51:01.225964Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TẢI MODEL TỪ CHECKPOINT 900\n",
      "Loading model from oopssuper96/speecht5_finetuned_emirhan_tr (commit 9367721)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1914143e22c463ab88c6cf5c2a75a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d93409295ed49329c25d383255674f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/578M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5e056baf7e47dabe2b7b87bd68d3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"TẢI MODEL TỪ CHECKPOINT 900\")\n",
    "print(f\"Loading model from {base_repo_path} (commit {checkpoint_revision})...\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\n",
    "    base_repo_path, \n",
    "    revision=checkpoint_revision\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.generate = partial(model.generate, use_cache=True)\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T09:54:02.119466Z",
     "iopub.status.busy": "2025-11-05T09:54:02.118827Z",
     "iopub.status.idle": "2025-11-05T13:03:22.841187Z",
     "shell.execute_reply": "2025-11-05T13:03:22.840446Z",
     "shell.execute_reply.started": "2025-11-05T09:54:02.119440Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "LƯU Ý: Thanh progress bar sẽ đếm lại từ 0, nhưng model đang train VẪN LÀ model 900 steps.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 3:09:07, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.507986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.523200</td>\n",
       "      <td>0.503110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.514100</td>\n",
       "      <td>0.500485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.500243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.492400</td>\n",
       "      <td>0.499753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>0.498179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.482700</td>\n",
       "      <td>0.504790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.501308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HOÀN TẤT HUẤN LUYỆN! ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"speecht5_finetuned_emirhan_tr\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_steps=100,\n",
    "    max_steps=4000, \n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False}, \n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=1,\n",
    "    save_steps=500, \n",
    "    eval_steps=500,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=False,\n",
    "    label_names=[\"labels\"],\n",
    "    push_to_hub=True, \n",
    ")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=processor, \n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"LƯU Ý: Thanh progress bar sẽ đếm lại từ 0, nhưng model đang train VẪN LÀ model 900 steps.\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"=== HOÀN TẤT HUẤN LUYỆN! ===\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNsW0zQ0tPqXkmaYKiUxzxN",
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
