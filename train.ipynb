{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d21990",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==== CELL 1: INSTALL & SETUP ====\n",
    "# Th√™m 'torchvision' v√†o ƒë√¢y ƒë·ªÉ ƒë·ªìng b·ªô phi√™n b·∫£n v·ªõi torch v√† torchaudio\n",
    "!pip install -q \"TTS>=0.22.0\" \"torch<2.6\" torchaudio torchvision transformers datasets accelerate torchcodec\n",
    "\n",
    "!pip install -q librosa soundfile pyarrow pyyaml tqdm\n",
    "\n",
    "!apt-get update -qq && apt-get install -y espeak-ng ffmpeg\n",
    "\n",
    "import os, torch, warnings, pathlib\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Kaggle cache dirs (gi·∫£m l·ªói out-of-quota / write-permission)\n",
    "os.environ[\"HF_HOME\"] = \"/kaggle/working/hf_home\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/kaggle/working/hf_datasets\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = \"/kaggle/working/hf_hub\"\n",
    "for d in [\"/kaggle/working/hf_home\", \"/kaggle/working/hf_datasets\", \"/kaggle/working/hf_hub\"]:\n",
    "    pathlib.Path(d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.2f} GB\")\n",
    "print(\"‚úÖ Setup done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a1a24",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==== CELL 3: SHARD DATA PREP ====\n",
    "import os, gc, numpy as np, pyarrow.parquet as pq, soundfile as sf, librosa\n",
    "from io import BytesIO\n",
    "from huggingface_hub import hf_hub_download\n",
    "from tqdm import tqdm\n",
    "\n",
    "REPO_ID = \"NhutP/VietSpeech\"                     # Dataset HF (ƒë√∫ng theo b·∫°n n√™u)\n",
    "DATASET_DIR = \"/kaggle/working/xtts_dataset\"     # Th∆∞ m·ª•c c·ªë ƒë·ªãnh cho XTTS\n",
    "WAV_DIR = f\"{DATASET_DIR}/wavs\"\n",
    "os.makedirs(WAV_DIR, exist_ok=True)\n",
    "\n",
    "def build_metadata_for_shard(\n",
    "    shard_idx: int,\n",
    "    repo_id: str = REPO_ID,\n",
    "    max_samples: int = 2000,     # s·ªë m·∫´u m·ªói shard (t√πy VRAM/dung l∆∞·ª£ng)\n",
    "    min_dur: float = 1.0,\n",
    "    max_dur: float = 15.0,\n",
    "    target_sr: int = 22050\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    - T·∫£i 1 shard parquet -> gi·∫£i m√£ audio h·ª£p l·ªá -> l∆∞u WAV 16-bit mono 22.05kHz\n",
    "    - Ghi ƒê√à metadata.csv (format XTTS): audio_file|text|speaker_name|language\n",
    "    - Tr·∫£ v·ªÅ s·ªë m·∫´u ƒë√£ ghi\n",
    "    \"\"\"\n",
    "    # X√≥a WAV c≈© ƒë·ªÉ tr·ªëng ch·ªó\n",
    "    for fn in os.listdir(WAV_DIR):\n",
    "        try: os.remove(os.path.join(WAV_DIR, fn))\n",
    "        except: pass\n",
    "\n",
    "    metadata_lines = []\n",
    "    written = 0\n",
    "\n",
    "    filename = f\"data/train-{shard_idx:05d}-of-00027.parquet\"\n",
    "    local_path = None\n",
    "    try:\n",
    "        print(f\"\\nüì• Shard {shard_idx+1}/27 ‚Üí {filename}\")\n",
    "        local_path = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"dataset\")\n",
    "        pf = pq.ParquetFile(local_path)\n",
    "\n",
    "        for batch in pf.iter_batches(batch_size=256):\n",
    "            batch_dict = batch.to_pydict()\n",
    "            n = len(batch_dict[\"audio\"])\n",
    "            for i in range(n):\n",
    "                if written >= max_samples: break\n",
    "                try:\n",
    "                    audio_item = batch_dict[\"audio\"][i]\n",
    "                    audio_bytes = audio_item[\"bytes\"]\n",
    "                    wav, sr = sf.read(BytesIO(audio_bytes))  # np.float\n",
    "\n",
    "                    dur = len(wav)/sr\n",
    "                    if dur < min_dur or dur > max_dur:\n",
    "                        continue\n",
    "\n",
    "                    # resample & mono\n",
    "                    if sr != target_sr:\n",
    "                        wav = librosa.resample(wav, orig_sr=sr, target_sr=target_sr)\n",
    "                    if wav.ndim > 1:\n",
    "                        wav = wav.mean(axis=1)\n",
    "\n",
    "                    # normalize & quantize PCM_16 (ti·∫øt ki·ªám dung l∆∞·ª£ng)\n",
    "                    if np.max(np.abs(wav)) > 0:\n",
    "                        wav = wav/np.max(np.abs(wav))*0.95\n",
    "                    wav_i16 = (wav * 32767.0).astype(np.int16)\n",
    "\n",
    "                    # text\n",
    "                    text = batch_dict.get(\"transcription\", [None])[i] or batch_dict.get(\"text\", [None])[i] or \"\"\n",
    "                    text = text.strip()\n",
    "                    if not (3 <= len(text) <= 500):\n",
    "                        continue\n",
    "\n",
    "                    # save wav\n",
    "                    out_name = f\"vi_{shard_idx:02d}_{written:06d}.wav\"\n",
    "                    out_path = os.path.join(WAV_DIR, out_name)\n",
    "                    sf.write(out_path, wav_i16, target_sr, subtype=\"PCM_16\")\n",
    "\n",
    "                    # metadata row (XTTS: audio|text|speaker|language)\n",
    "                    speaker = f\"spk_{shard_idx:02d}\"\n",
    "                    metadata_lines.append(f\"{out_name}|{text}|{speaker}|vi\")\n",
    "\n",
    "                    written += 1\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if written >= max_samples:\n",
    "                break\n",
    "    finally:\n",
    "        if local_path and os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        gc.collect()\n",
    "\n",
    "    meta_path = os.path.join(DATASET_DIR, \"metadata.csv\")\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(metadata_lines))\n",
    "\n",
    "    print(f\"‚úÖ Shard {shard_idx+1}: wrote {written} samples ‚Üí {meta_path}\")\n",
    "    return written\n",
    "\n",
    "print(\"‚úÖ Shard prep functions ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80653a60",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==== CELL 3: SHARD DATA PREP ====\n",
    "import os, gc, numpy as np, pyarrow.parquet as pq, soundfile as sf, librosa\n",
    "from io import BytesIO\n",
    "from huggingface_hub import hf_hub_download\n",
    "from tqdm import tqdm\n",
    "\n",
    "REPO_ID = \"NhutP/VietSpeech\"                     # Dataset HF (ƒë√∫ng theo b·∫°n n√™u)\n",
    "DATASET_DIR = \"/kaggle/working/xtts_dataset\"     # Th∆∞ m·ª•c c·ªë ƒë·ªãnh cho XTTS\n",
    "WAV_DIR = f\"{DATASET_DIR}/wavs\"\n",
    "os.makedirs(WAV_DIR, exist_ok=True)\n",
    "\n",
    "def build_metadata_for_shard(\n",
    "    shard_idx: int,\n",
    "    repo_id: str = REPO_ID,\n",
    "    max_samples: int = 2000,     # s·ªë m·∫´u m·ªói shard (t√πy VRAM/dung l∆∞·ª£ng)\n",
    "    min_dur: float = 1.0,\n",
    "    max_dur: float = 15.0,\n",
    "    target_sr: int = 22050\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    - T·∫£i 1 shard parquet -> gi·∫£i m√£ audio h·ª£p l·ªá -> l∆∞u WAV 16-bit mono 22.05kHz\n",
    "    - Ghi ƒê√à metadata.csv (format XTTS): audio_file|text|speaker_name|language\n",
    "    - Tr·∫£ v·ªÅ s·ªë m·∫´u ƒë√£ ghi\n",
    "    \"\"\"\n",
    "    # X√≥a WAV c≈© ƒë·ªÉ tr·ªëng ch·ªó\n",
    "    for fn in os.listdir(WAV_DIR):\n",
    "        try: os.remove(os.path.join(WAV_DIR, fn))\n",
    "        except: pass\n",
    "\n",
    "    metadata_lines = []\n",
    "    written = 0\n",
    "\n",
    "    filename = f\"data/train-{shard_idx:05d}-of-00027.parquet\"\n",
    "    local_path = None\n",
    "    try:\n",
    "        print(f\"\\nüì• Shard {shard_idx+1}/27 ‚Üí {filename}\")\n",
    "        local_path = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"dataset\")\n",
    "        pf = pq.ParquetFile(local_path)\n",
    "\n",
    "        for batch in pf.iter_batches(batch_size=256):\n",
    "            batch_dict = batch.to_pydict()\n",
    "            n = len(batch_dict[\"audio\"])\n",
    "            for i in range(n):\n",
    "                if written >= max_samples: break\n",
    "                try:\n",
    "                    audio_item = batch_dict[\"audio\"][i]\n",
    "                    audio_bytes = audio_item[\"bytes\"]\n",
    "                    wav, sr = sf.read(BytesIO(audio_bytes))  # np.float\n",
    "\n",
    "                    dur = len(wav)/sr\n",
    "                    if dur < min_dur or dur > max_dur:\n",
    "                        continue\n",
    "\n",
    "                    # resample & mono\n",
    "                    if sr != target_sr:\n",
    "                        wav = librosa.resample(wav, orig_sr=sr, target_sr=target_sr)\n",
    "                    if wav.ndim > 1:\n",
    "                        wav = wav.mean(axis=1)\n",
    "\n",
    "                    # normalize & quantize PCM_16 (ti·∫øt ki·ªám dung l∆∞·ª£ng)\n",
    "                    if np.max(np.abs(wav)) > 0:\n",
    "                        wav = wav/np.max(np.abs(wav))*0.95\n",
    "                    wav_i16 = (wav * 32767.0).astype(np.int16)\n",
    "\n",
    "                    # text\n",
    "                    text = batch_dict.get(\"transcription\", [None])[i] or batch_dict.get(\"text\", [None])[i] or \"\"\n",
    "                    text = text.strip()\n",
    "                    if not (3 <= len(text) <= 500):\n",
    "                        continue\n",
    "\n",
    "                    # save wav\n",
    "                    out_name = f\"vi_{shard_idx:02d}_{written:06d}.wav\"\n",
    "                    out_path = os.path.join(WAV_DIR, out_name)\n",
    "                    sf.write(out_path, wav_i16, target_sr, subtype=\"PCM_16\")\n",
    "\n",
    "                    # metadata row (XTTS: audio|text|speaker|language)\n",
    "                    speaker = f\"spk_{shard_idx:02d}\"\n",
    "                    metadata_lines.append(f\"{out_name}|{text}|{speaker}|vi\")\n",
    "\n",
    "                    written += 1\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if written >= max_samples:\n",
    "                break\n",
    "    finally:\n",
    "        if local_path and os.path.exists(local_path):\n",
    "            try: os.remove(local_path)\n",
    "            except: pass\n",
    "        gc.collect()\n",
    "\n",
    "    meta_path = os.path.join(DATASET_DIR, \"metadata.csv\")\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(metadata_lines))\n",
    "\n",
    "    print(f\"‚úÖ Shard {shard_idx+1}: wrote {written} samples ‚Üí {meta_path}\")\n",
    "    return written\n",
    "\n",
    "print(\"‚úÖ Shard prep functions ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32e90c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==== CELL 4: WRITE XTTS FINETUNE CONFIG (YAML) ====\n",
    "import yaml, pathlib\n",
    "\n",
    "OUT_DIR = \"/kaggle/working/xtts_vietnamese\"     # n∆°i ghi checkpoint/logs\n",
    "CFG_PATH = f\"{OUT_DIR}/config_ft.yaml\"\n",
    "pathlib.Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = {\n",
    "    \"model\": \"xtts_v2\",                # model family\n",
    "    \"output_path\": OUT_DIR,\n",
    "    \"run_name\": \"xtts_vi_stream\",\n",
    "    \"logger\": \"tensorboard\",\n",
    "\n",
    "    # ==== DATASET ====\n",
    "    \"dataset_config\": [\n",
    "        {\n",
    "            \"formatter\": \"ljspeech\",   # d√πng formatter ljspeech: metadata + wavs\n",
    "            \"meta_file_train\": f\"{DATASET_DIR}/metadata.csv\",\n",
    "            \"meta_file_val\": f\"{DATASET_DIR}/metadata.csv\",   # t·∫°m th·ªùi d√πng chung\n",
    "            \"path\": DATASET_DIR,       # base path\n",
    "            \"audio_dir\": WAV_DIR,      # th∆∞ m·ª•c wavs\n",
    "            \"language\": \"vi\",\n",
    "            \"n_val\": 64,               # m·ªói shard validation t·∫°m 64 m·∫´u\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    # ==== AUDIO ====\n",
    "    \"audio\": {\n",
    "        \"sample_rate\": 22050,\n",
    "        \"num_mels\": 80,          # XTTS d√πng mel-80 n·ªôi b·ªô (kh√¥ng c·∫ßn t·ª± t√≠nh)\n",
    "        \"fft_size\": 1024,\n",
    "        \"hop_length\": 256\n",
    "    },\n",
    "\n",
    "    # ==== OPTIMIZATION ====\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"adamw\",\n",
    "        \"lr\": 5e-5,\n",
    "        \"betas\": [0.9, 0.98],\n",
    "        \"eps\": 1e-9,\n",
    "        \"weight_decay\": 0.0\n",
    "    },\n",
    "\n",
    "    # ==== TRAINER ====\n",
    "    \"trainer\": {\n",
    "        \"max_steps\": 1500,       # s·∫Ω b·ªã ghi ƒë√® m·ªói shard\n",
    "        \"eval_steps\": 250,\n",
    "        \"save_step\": 500,\n",
    "        \"log_step\": 50,\n",
    "        \"precision\": \"fp16\",\n",
    "        \"batch_size\": 2,\n",
    "        \"grad_accum\": 4,         # effective batch ~8\n",
    "        \"num_workers\": 2,\n",
    "        \"pin_memory\": True,\n",
    "        \"cudnn_benchmark\": True,\n",
    "        \"seed\": 42\n",
    "    },\n",
    "\n",
    "    # ==== LOSSES (ƒë·ªÉ trainer t·ª± c·∫•u h√¨nh m·∫∑c ƒë·ªãnh XTTS) ====\n",
    "    \"losses\": {\n",
    "        \"use_xtts_defaults\": True\n",
    "    },\n",
    "\n",
    "    # ==== FREEZE POLICY (nh·∫π nh√†ng; c√≥ th·ªÉ b·ªè n·∫øu mu·ªën full) ====\n",
    "    \"freeze\": {\n",
    "        # g·ª£i √Ω: cho ph√©p GPT + decoder h·ªçc; freeze ph·∫ßn √≠t quan tr·ªçng\n",
    "        \"freeze_encoder\": False,\n",
    "        \"freeze_gpt\": False,\n",
    "        \"freeze_decoder\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(CFG_PATH, \"w\") as f:\n",
    "    yaml.safe_dump(config, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(\"‚úÖ Wrote YAML:\", CFG_PATH)\n",
    "print(open(CFG_PATH).read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8a5dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"heellloo\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
